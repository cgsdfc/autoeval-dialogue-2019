% MIT License
% 
% Copyright (c) 2019 Cong Feng
% 
% Permission is hereby granted, free of charge, to any person obtaining a copy
% of this software and associated documentation files (the "Software"), to deal
% in the Software without restriction, including without limitation the rights
% to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
% copies of the Software, and to permit persons to whom the Software is
% furnished to do so, subject to the following conditions:
% 
% The above copyright notice and this permission notice shall be included in all
% copies or substantial portions of the Software.
% 
% THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
% IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
% FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
% AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
% LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
% OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
% SOFTWARE.

% 任务书中的信息

%% 原始资料及设计要求
\assignReq
{由三部分组成：学术论文、数据集和项目工程。其中学术论文主要为发表}
{在人工智能和计算语言学等领域的国际顶级期刊的论文。数据集主要为训}
{练对话系统的结构化或者非结构化的对话预料库。项目工程则是实现了某}
{一模型的，用于定量实验的程序。设计要求为理解对话系统中各种评价指}
{标的原理、优点和局限性。}

%% 工作内容
\assignWork
{本课题力求对现有的面向生成的对话系统的评价指标做一个尽可能完备的}
{文献综述。在对话系统领域，由于人类对话的多样性和歧义性，评价系统}
{输出的响应是一个比较困难的问题，也是一个开放的学术问题。本文的工}
{作是把目前所有的评价指标都整理出来，对它们作逐一的考察，在考察现}
{在的评价指标的基础上，本文将分析不同评价指标在不同的数据集上的特}
{点，总结出好的指标应该具有的优点，促进对话系统评估的自动化。}

%% 参考文献
\assignRef
{How NOT to Evaluate Your Dialogue System: An Empirical Study of Unsupervised}
{Metrics for Response Generation (Liu et al. 2016)}
{Building End-To-End Dialogue Systems Using Generative Hierarchical Neural}
{Network Model (Serban et al. 2016)}
{A Survey of Available Corpora for Building Data-Driven Dialogue Systems}
{(Serban et al.)}
{BLEU: A Method for Automatic Evalutation of Machine Translation}
{(Kishore Papineni et al. 2002)}
% Extra line causes a bug in the first page. Very serious bug.
%{Towards an Automatic Turing Test: Learning to Evaluate Dialogue Response}
%{Ryan Lowe et al. 2007}
